{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-performance computing in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#High-performance-computing-in-Python-\" data-toc-modified-id=\"High-performance-computing-in-Python--1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>High-performance computing in Python <a class=\"tocSkip\"></a></a></div><div class=\"lev2 toc-item\"><a href=\"#HPC-on-the-ICL-clusters\" data-toc-modified-id=\"HPC-on-the-ICL-clusters-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>HPC on the ICL clusters</a></div><div class=\"lev3 toc-item\"><a href=\"#Preparing-scripts-for-running-on-the-HPC\" data-toc-modified-id=\"Preparing-scripts-for-running-on-the-HPC-111\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Preparing scripts for running on the HPC</a></div><div class=\"lev1 toc-item\"><a href=\"#Copying-scripts-from-your-computer-to-the-HPC-server\" data-toc-modified-id=\"Copying-scripts-from-your-computer-to-the-HPC-server-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Copying scripts from your computer to the HPC server</a></div><div class=\"lev1 toc-item\"><a href=\"#Running-scripts-on-the-HPC\" data-toc-modified-id=\"Running-scripts-on-the-HPC-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Running scripts on the HPC</a></div><div class=\"lev1 toc-item\"><a href=\"#Readings-&amp;-Resources\" data-toc-modified-id=\"Readings-&amp;-Resources-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Readings \\&amp; Resources</a></div><div class=\"lev4 toc-item\"><a href=\"#Readings-&amp;-Resources\" data-toc-modified-id=\"Readings-&amp;-Resources-4001\"><span class=\"toc-item-num\">4.0.0.1&nbsp;&nbsp;</span>Readings &amp; Resources</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "\n",
    "<  | [Back to Mathematical modelling in Jupyter -->](Jupyter-Maths.ipynb) >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter introduces you to HPC in python using of the [Imperial College HPC](https://wiki.imperial.ac.uk/display/HPC/Introduction). \n",
    "\n",
    "Note that there are a number of ways in which you can develop HPC implementations for your code locally (on your own computer). I will not cover these, but here is a list:\n",
    "\n",
    "* Ipython [parallel](https://ipython.org/ipython-doc/3/parallel/)\n",
    "* Multi-threading, using the [threading](https://docs.python.org/3/library/threading.html) package.\n",
    "* Using multiple processors with the [multiprocessing](https://docs.python.org/2/library/multiprocessing.html) package  \n",
    "\n",
    "The difference between threading and muliprcocessing is that threads share in the same memory space, while processes have separate memory spaces. This makes it a harder to share information between processes with multiprocessing, but this is till a useful approach for quick and dirty parallelization. When better communication between processes is required, sophisticated solutions such as MPI and OpenMP may be needed.The MPI (Message Passing Interface) standard/protocol can be used in Python to parallelize your code over multiple processors thorugh the [mpi4py](http://mpi4py.scipy.org/docs/usrman/index.html) package. You also parallelize scipy/numpy array loops with [Cython and OpenMP](http://www.perrygeo.com/parallelizing-numpy-array-loops-with-cython-and-mpi.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPC on the ICL clusters\n",
    "\n",
    "The flowing instructions also apply, with suitable modifications, for R scripts.\n",
    "\n",
    "### Preparing scripts for running on the HPC\n",
    "\n",
    "The script you will run needs a sha-bang (telling it what shell to run, usually bash), you need to allocate resources to PBS (such as walltime, number of processors, and memory , using the `\\#PBS` directive, and tell it what Python script to run. The bash script could look something [like this](../silbiocomp/Practicals/Code//PythonHPC.sh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Or, you can do something like this to move all files one-by-one to \n",
    "avoid exceeding memory allocation ({\\tt *.p} indicates that you used \n",
    "{\\tt pickle} to dump results):\n",
    "\n",
    "\\begin{lstlisting}\n",
    "for f in *.p; do\n",
    "\techo \"Processing $f...\"\n",
    "\tmv $f $WORK/TestPyHPC/output/\n",
    "done\n",
    "\\end{lstlisting}\n",
    "\n",
    "NOTE: Most of the cx1 nodes have multiple cores, so there's no fixed memory assigned to each core. If you use more memory than your request on your \\#PBS directive, your job is likely to be terminated. If you request more memory than is available, the job will remain queued until sufficient memory is free \n",
    "for the job to run\n",
    "\n",
    "PBS also  allows  you  to  submit jobs using a Python (instead of \n",
    "shell) script as well. Look up the qsub manual ({\\tt man qsub}) in the \n",
    "HPC terminal, or visit \n",
    "\\url{https://gist.github.com/nobias/5b2373258e595e5242d5}\n",
    "\n",
    "Your HPC enabled Python code could look like this:\n",
    "\n",
    "\\lstinputlisting{Practicals/Code/MyHPCScript.py}\n",
    "\n",
    "% In your Python code you need to set the environment so that it\n",
    "% knows its working directory and where to output files:\n",
    "\n",
    "% \\begin{lstlisting}\n",
    "  % home <- os.getenv('HOME')\n",
    "  % ..\n",
    "  % save(object, file=`home/whatever/object.RData')\n",
    "% \\end{lstlisting}\n",
    "\n",
    "\\section{Copying scripts from your computer to the HPC server}\n",
    " \n",
    "Secure copy bash script file to {\\tt \\$HOME} on HPC server following\n",
    "{\\tt \\$ scp source host:destination} structure, e.g.:\n",
    "\n",
    "\\begin{lstlisting}\n",
    "$ scp script.sh user@login.cx1.hpc.ic.ac.uk:/home/user/whatever/script.sh\n",
    "\\end{lstlisting}\n",
    "\n",
    "\\section{Running scripts on the HPC}\n",
    "\n",
    "Open a secure shell (ssh):\n",
    "\n",
    "\\begin{lstlisting}\n",
    "$ ssh user@login.cx1.hpc.ic.ac.uk\n",
    "\\end{lstlisting}\n",
    "\n",
    "Check for available modules:\n",
    "\n",
    "\\begin{lstlisting}\n",
    "$ module avail\n",
    "\\end{lstlisting}\n",
    "\n",
    "Your job then needs to be queued using {\\tt qsub} (PBS):\n",
    "\n",
    "\\begin{lstlisting}\n",
    "  $ qsub -j eo script.sh\n",
    "\\end{lstlisting}\n",
    "\n",
    "where {\\tt -j eo} is an option to join both output and error into one \n",
    "file. Running the script will produce a job output (anything that is \n",
    "printed in the shell terminal (e.g. {\\tt echo})), and an error file \n",
    "(related to whether the script was successful or not), in the form of \n",
    "\\{scriptname\\}.o\\{job id\\} and \\{scriptname\\}.e\\{jobid\\}.\\\\\n",
    "\n",
    "The {\\tt qstat} command provides information on the job being submitted \n",
    "(which queue (short, medium, long), status, etc.) as well as \n",
    "information on all queues available (-q, -Q).\n",
    "\n",
    "\\section{Readings \\& Resources}\n",
    "IC library gives you with access to several e- and paper books on UNIX, some \n",
    "specific to Ubuntu. Browse or search and find a good intro book.\n",
    "\n",
    "\\begin{itemize}\n",
    "  \\itemsep6pt\n",
    "  \\item The ICL HPC wiki is a very useful resource: \\url{https://wiki.imperial.ac.uk/display/HPC/Command+line}\n",
    "\\end{itemize}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Readings & Resources\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "153px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
