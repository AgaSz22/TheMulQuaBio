
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{NLLS}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \section{Non-linear least Squares Fitting in Ecology and Evolution
}\label{non-linear-least-squares-fitting-in-ecology-and-evolution}

    \hypertarget{toc}{}

    \subsection{Introduction and
preliminaries}\label{introduction-and-preliminaries}

This chapter assumes that you have already seen the
\href{https://github.com/mhasoba/TheMulQuaBio/blob/master/Lectures/NLLS/Pawar_NLLS.pdf}{NLLS
lecture} and/or its
\href{https://imperial.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=2aa5bbb4-e1d0-44a1-adea-a87000aab72f}{recording}.

We will work with several NLLS examples here.

\begin{quote}
\emph{You should build a separate R scripts for each of these examples
using the principles of good coding you learnt in the R week}. In
particular, create separate \texttt{code}, \texttt{data},
\texttt{results} directories, and \texttt{setwd()} to \texttt{code}.

For example, for the Allometry example below, create a new R script file
called \texttt{Allometry\_nlls.R} and save it to your \texttt{code}
directory. Then build your script for tackling this particular example
in that file.
\end{quote}

You may work in RStudio or any other Code editor you prefer.

You will need the \texttt{nls.lm} R package, which you can install using
the standard method (linux users, launch R in \texttt{sudo} mode first):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{>}\StringTok{ }\KeywordTok{install.packages}\NormalTok{(}\StringTok{"minpack.lm"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

    Now, load the necessary packages, and clear all variables and graphic
devices:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{k+kp}{rm}\PY{p}{(}\PY{k+kt}{list} \PY{o}{=} \PY{k+kp}{ls}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        graphics.off\PY{p}{(}\PY{p}{)}
        
        \PY{k+kn}{library}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{minpack.lm\PYZdq{}}\PY{p}{)} \PY{c+c1}{\PYZsh{} for Levenberg\PYZhy{}Marquardt nls fitting}
        \PY{k+kn}{library}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{ggplot2\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \emph{You will need to repeat these commands at the start of every new
nlls script file you develop below.}

    \subsubsection{Why use the nls.lm
package?}\label{why-use-the-nls.lm-package}

The standard NLLS function in R, cals \texttt{nls} uses a less robust
algorithm called the Gauss-Newton algorithm. Therefore, \texttt{nls}
will often fail to fit your model to the data if you start off at
starting values for the parameters that are too far from what the
optimal vaues would be, especially if the "parameter space" is weirdly
shaped, i.e., the model has a mathematical form that makes it hard to
find parameter combinations that minimize the NLLS. If this does not
makes ense, don't worry about it- just go with \texttt{nls\_LM} from the
\texttt{nls.lm} package instead of \texttt{nls}! If you are really
curious, try substituting \texttt{nls} for \texttt{nls\_LM} in the
examples below and compare the results.

    \subsection{Allometric scaling}\label{allometric-scaling}

Let's start with a common and reasonably simple example from biology:
\href{https://en.wikipedia.org/wiki/Allometry}{allometric scaling}. We
will look at allometric scaling of body weight vs. total body length in
dragonflies and damselfiles.

Allometric relationships take the form:

    \begin{equation} \label{eq:allom}
y = a x^b
\end{equation}

    where \(x\) and \(y\) are morphological measures (body length and body
weight respectively, in our current example), the constant is the value
of \(y\) at body length \(x = 1\) unit, and \(b\) is the scaling
"exponent". This is also called a power-law, because \(y\) relates to
\(x\) through a simple power.

First create a function object for the power law model:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} powMod \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kr}{function}\PY{p}{(}x\PY{p}{,} a\PY{p}{,} b\PY{p}{)} \PY{p}{\PYZob{}}
            \PY{k+kr}{return}\PY{p}{(}a \PY{o}{*} x\PY{o}{\PYZca{}}b\PY{p}{)}
        \PY{p}{\PYZcb{}}
\end{Verbatim}


    Now read in the
\href{https://raw.githubusercontent.com/mhasoba/TheMulQuaBio/master/Data/GenomeSize.csv}{data}
(first click on link and use "Save as" or \texttt{Ctrl+S} to download it
as a csv):

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} MyData \PY{o}{\PYZlt{}\PYZhy{}} read.csv\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{../Data/GenomeSize.csv\PYZdq{}}\PY{p}{)}
        
        \PY{k+kp}{head}\PY{p}{(}MyData\PY{p}{)}
\end{Verbatim}


    \begin{tabular}{r|llllllllllllllll}
 Suborder & Family & Species & GenomeSize & GenomeSE & GenomeN & BodyWeight & TotalLength & HeadLength & ThoraxLength & AdbdomenLength & ForewingLength & HindwingLength & ForewingArea & HindwingArea & MorphologyN\\
\hline
	 Anisoptera           & Aeshnidae            & Aeshna canadensis    & 2.20                 &   NA                 & 1                    & 0.159                & 67.58                & 6.83                 & 11.81                & 48.94                & 45.47                & 45.40                & 369.57               & 483.61               & 2                   \\
	 Anisoptera           & Aeshnidae            & Aeshna constricta    & 1.76                 & 0.06                 & 4                    & 0.228                & 71.97                & 6.84                 & 10.72                & 54.41                & 46.00                & 45.48                & 411.15               & 517.38               & 3                   \\
	 Anisoptera           & Aeshnidae            & Aeshna eremita       & 1.85                 &   NA                 & 1                    & 0.312                & 78.80                & 6.27                 & 16.19                & 56.33                & 51.24                & 49.47                & 460.72               & 574.33               & 1                   \\
	 Anisoptera           & Aeshnidae            & Aeshna tuberculifera & 1.78                 & 0.10                 & 2                    & 0.218                & 72.44                & 6.62                 & 12.53                & 53.29                & 49.84                & 48.82                & 468.74               & 591.42               & 2                   \\
	 Anisoptera           & Aeshnidae            & Aeshna umbrosa       & 2.00                 &   NA                 & 1                    & 0.207                & 73.05                & 4.92                 & 11.11                & 57.03                & 46.51                & 45.97                & 382.48               & 481.44               & 1                   \\
	 Anisoptera           & Aeshnidae            & Aeshna verticalis    & 1.59                 &   NA                 & 1                    & 0.220                & 66.25                & 6.48                 & 11.64                & 48.13                & 45.91                & 44.91                & 400.40               & 486.97               & 1                   \\
\end{tabular}


    
    \href{https://en.wikipedia.org/wiki/Dragonfly}{Anisoptera} are
dragonflies, and
\href{https://en.wikipedia.org/wiki/Damselfly}{Zygoptera} are
Damselflies. The variables of interest are \texttt{BodyWeight} and
\texttt{TotalLength}. Let's use the dragonflies data subset.

    So subset the data accordingly and remove NAs:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} Data2Fit \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kp}{subset}\PY{p}{(}MyData\PY{p}{,}Suborder \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{Anisoptera\PYZdq{}}\PY{p}{)}
        
        Data2Fit \PY{o}{\PYZlt{}\PYZhy{}} Data2Fit\PY{p}{[}\PY{o}{!}\PY{k+kp}{is.na}\PY{p}{(}Data2Fit\PY{o}{\PYZdl{}}TotalLength\PY{p}{)}\PY{p}{,}\PY{p}{]} \PY{c+c1}{\PYZsh{} remove NA\PYZsq{}s}
\end{Verbatim}


    Plot it:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} plot\PY{p}{(}Data2Fit\PY{o}{\PYZdl{}}TotalLength\PY{p}{,} Data2Fit\PY{o}{\PYZdl{}}BodyWeight\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_17_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} ggplot\PY{p}{(}Data2Fit\PY{p}{,} aes\PY{p}{(}x \PY{o}{=} TotalLength\PY{p}{,} y \PY{o}{=} BodyWeight\PY{p}{)}\PY{p}{)} \PY{o}{+} geom\PYZus{}point\PY{p}{(}\PY{p}{)} \PY{c+c1}{\PYZsh{} or using ggplot!}
\end{Verbatim}


    
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_18_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Now fit the model to the data using NLLS:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} PowFit \PY{o}{\PYZlt{}\PYZhy{}} nlsLM\PY{p}{(}BodyWeight \PY{o}{\PYZti{}} powMod\PY{p}{(}TotalLength\PY{p}{,} a\PY{p}{,} b\PY{p}{)}\PY{p}{,} data \PY{o}{=} Data2Fit\PY{p}{,} start \PY{o}{=} \PY{k+kt}{list}\PY{p}{(}a \PY{o}{=} \PY{l+m}{.1}\PY{p}{,} b \PY{o}{=} \PY{l+m}{.1}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    We can use \texttt{summary()} just like we would for a \texttt{lm()} fit
object.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{k+kp}{summary}\PY{p}{(}PowFit\PY{p}{)}
\end{Verbatim}


    
    \begin{verbatim}

Formula: BodyWeight ~ powMod(TotalLength, a, b)

Parameters:
   Estimate Std. Error t value Pr(>|t|)    
a 3.941e-06  2.234e-06   1.764    0.083 .  
b 2.585e+00  1.348e-01  19.174   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.02807 on 58 degrees of freedom

Number of iterations to convergence: 39 
Achieved convergence tolerance: 1.49e-08

    \end{verbatim}

    
    Most of the output is analogous to the output of an \texttt{lm()}.
However, further statistucal inference here cannot be done using
Analysis of Variance (ANOVA) (), because the mdoel is not a Linear
Model. Try \texttt{anova(PowFit)}, and see what happens. The
\texttt{Number\ of\ iterations\ to\ convergence:\ 39}, and
\texttt{Achieved\ convergence\ tolerance:\ 1.49e-08} stem from the fact
that NLLS requires computer simulations; revisit the
\href{https://github.com/mhasoba/TheMulQuaBio/blob/master/Lectures/NLLS/Pawar_NLLS.pdf}{Lecture}
for an explanation of this.

    Now let's visualize the fit. For this, first we need to generate a
vector of body lengths (the x-axis variable) for plotting:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} Lengths \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kp}{seq}\PY{p}{(}\PY{k+kp}{min}\PY{p}{(}Data2Fit\PY{o}{\PYZdl{}}TotalLength\PY{p}{)}\PY{p}{,}\PY{k+kp}{max}\PY{p}{(}Data2Fit\PY{o}{\PYZdl{}}TotalLength\PY{p}{)}\PY{p}{,}len\PY{o}{=}\PY{l+m}{200}\PY{p}{)}
\end{Verbatim}


    Next, calculate the predicted line. For this, we will need to extract
the coefficient from the model fit object using the
\texttt{coef()}command.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} coef\PY{p}{(}PowFit\PY{p}{)}\PY{p}{[}\PY{l+s}{\PYZdq{}}\PY{l+s}{a\PYZdq{}}\PY{p}{]}
         coef\PY{p}{(}PowFit\PY{p}{)}\PY{p}{[}\PY{l+s}{\PYZdq{}}\PY{l+s}{b\PYZdq{}}\PY{p}{]}
\end{Verbatim}


    \textbf{a:} 3.94068491030517e-06

    
    \textbf{b:} 2.58504796772587

    
    So, we can do the following:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} Predic2PlotPow \PY{o}{\PYZlt{}\PYZhy{}} powMod\PY{p}{(}Lengths\PY{p}{,}coef\PY{p}{(}PowFit\PY{p}{)}\PY{p}{[}\PY{l+s}{\PYZdq{}}\PY{l+s}{a\PYZdq{}}\PY{p}{]}\PY{p}{,}coef\PY{p}{(}PowFit\PY{p}{)}\PY{p}{[}\PY{l+s}{\PYZdq{}}\PY{l+s}{b\PYZdq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    Now plot the data and the fitted model line:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} plot\PY{p}{(}Data2Fit\PY{o}{\PYZdl{}}TotalLength\PY{p}{,} Data2Fit\PY{o}{\PYZdl{}}BodyWeight\PY{p}{)}
         lines\PY{p}{(}Lengths\PY{p}{,} Predic2PlotPow\PY{p}{,} col \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{blue\PYZsq{}}\PY{p}{,} lwd \PY{o}{=} \PY{l+m}{2.5}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_31_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    We can claculate the confidence intervals on the estimated parameters as
we would in OLS fitting used for Linear Models:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} confint\PY{p}{(}PowFit\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Waiting for profiling to be done{\ldots}

    \end{Verbatim}

    \begin{tabular}{r|ll}
  & 2.5\% & 97.5\%\\
\hline
	a & 1.171935e-06 & 1.205273e-05\\
	b & 2.318292e+00 & 2.872287e+00\\
\end{tabular}


    
    As you learnt before, a coefficient's CI should not include zero for it
to be statistically significant (different from zero).

    \paragraph{Exercises }\label{exercises}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\item
  Make the same plot as above, fitted line and all, in \texttt{ggplot},
  and add (display) the equation you estimated to your new (ggplot)
  plot. The equation is:
  \(\text{Weight} = 3.94 \times 10^{-06} \times \text{Length}^{2.59}\)
\item
  Try playing with the starting values, and see if you can "break" the
  model fit -\/- that is the NLLS fitting does not converge on a
  solution.
\item
  Repeat the model fitting (incuding a-b above) using the Zygoptera data
  subset.
\item
  There is an alternative (and in fact, more commonly-used) approach for
  fitting the allometric model to data: using Oridinary Least Squares on
  bi-logarithamically transformed data. That is, if you take a log of
  both sides of the Section \ref{eqallom} we get,
\end{enumerate}

\[
\log(y) = \log(a) + b \log(x)
\]

This is a straight line equation of the form \$c = d + b z \$, where
\(c = \log(c)\), \(d = \log(a)\), \(z = \log(x)\), and \(b\) is now the
slope parameter. So you can use Ordinary Least Squares and the linear
models framework (with \texttt{lm()}) in R to estimate the parameters of
the allometric equation.

In this exercise, try comparing the NLLS vs OLS methods to se how much
difference you get in the parameter estimates between them. For example,
see the methods used in this paper by
\href{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3465447/}{Cohen et al
2012}.

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{4}
\item
  The allometry between Body weight and Length is not the end of the
  story, you have a number of other linear morphological measurements
  (\texttt{HeadLength}, \texttt{ThoraxLength}, \texttt{AdbdomenLength},
  \texttt{ForewingLength}, \texttt{HindwingLength},
  \texttt{ForewingArea}, and \texttt{HindwingArea}) that can also be
  investigated. In this exercise, you will try two lines of
  investigation (again, repeated separately for Dragonflies and
  Damselfiles):

  \begin{enumerate}
  \def\labelenumii{(\roman{enumii})}
  \item
    How do each of these measurs allometrically scale with Body length
    (obtain estimates of scaling constant and exponent)? (Hint: you may
    want to use the \texttt{pairs()} command in R to get an overview of
    all the pairs of potential scaling relationships.
  \item
    Do any of the linear morphological measurements other than body
    length better predict Body weight? That is, does body weight scale
    more tightly with a linear morphological measurement other than
    total body length?
  \end{enumerate}
\end{enumerate}

    \subsubsection{Comparing two models}\label{comparing-two-models}

\emph{How do we know that there isn't a better or alternative model that
adequately explains the pattern in your dataset?}

This is important consideration in all data analyses (and more
generally, the scientific method!), so you must aim to compare your NLLS
model with an one or more alternatives for a more extensive and reliable
investigation of the problem.

Let's use model comparison to investigate whether the relationship
between body weight and length we found above is indeed allometric. For
this, we need an alternative model that can be fitted to the same data.
Let's try a quadratic curve, which is of the form:

\[y = a + b x + c x^2\]

This can also capture curvature in data, just as the
Section \ref{eqallom}. Note that this mode is linear in its parameters
(a linear model), which You can fit to the simply data using your
favorite \texttt{lm()} function:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}15}]:} QuaFit \PY{o}{\PYZlt{}\PYZhy{}} lm\PY{p}{(}BodyWeight \PY{o}{\PYZti{}} poly\PY{p}{(}TotalLength\PY{p}{,}\PY{l+m}{2}\PY{p}{)}\PY{p}{,} data \PY{o}{=} Data2Fit\PY{p}{)}
\end{Verbatim}


    And like before, we obtain the predicted values (but this time using the
\texttt{predict.lm} function):

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}16}]:} Predic2PlotQua \PY{o}{\PYZlt{}\PYZhy{}} predict.lm\PY{p}{(}QuaFit\PY{p}{,} \PY{k+kt}{data.frame}\PY{p}{(}TotalLength \PY{o}{=} Lengths\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    Now let's plot the two fitted models together:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}17}]:} plot\PY{p}{(}Data2Fit\PY{o}{\PYZdl{}}TotalLength\PY{p}{,} Data2Fit\PY{o}{\PYZdl{}}BodyWeight\PY{p}{)}
         lines\PY{p}{(}Lengths\PY{p}{,} Predic2PlotPow\PY{p}{,} col \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{blue\PYZsq{}}\PY{p}{,} lwd \PY{o}{=} \PY{l+m}{2.5}\PY{p}{)}
         lines\PY{p}{(}Lengths\PY{p}{,} Predic2PlotQua\PY{p}{,} col \PY{o}{=} \PY{l+s}{\PYZsq{}}\PY{l+s}{red\PYZsq{}}\PY{p}{,} lwd \PY{o}{=} \PY{l+m}{2.5}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_41_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Very similar fits, except that the quadratic model seems to get it wrong
at the lower end of the data range. Let's do a proper/formal model
comparison now to check which model better-fits the data.

Let's first calculate the R\(^2\) values of the two fitted models:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} RSS\PYZus{}Pow \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kp}{sum}\PY{p}{(}residuals\PY{p}{(}PowFit\PY{p}{)}\PY{o}{\PYZca{}}\PY{l+m}{2}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Residual sum of squares}
         TSS\PYZus{}Pow \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kp}{sum}\PY{p}{(}\PY{p}{(}Data2Fit\PY{o}{\PYZdl{}}BodyWeight \PY{o}{\PYZhy{}} \PY{k+kp}{mean}\PY{p}{(}Data2Fit\PY{o}{\PYZdl{}}BodyWeight\PY{p}{)}\PY{p}{)}\PY{o}{\PYZca{}}\PY{l+m}{2}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Total sum of squares}
         RSq\PYZus{}Pow \PY{o}{\PYZlt{}\PYZhy{}} \PY{l+m}{1} \PY{o}{\PYZhy{}} \PY{p}{(}RSS\PYZus{}Pow\PY{o}{/}TSS\PYZus{}Pow\PY{p}{)}  \PY{c+c1}{\PYZsh{} R\PYZhy{}squared value}
         
         RSS\PYZus{}Qua \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kp}{sum}\PY{p}{(}residuals\PY{p}{(}QuaFit\PY{p}{)}\PY{o}{\PYZca{}}\PY{l+m}{2}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Residual sum of squares}
         TSS\PYZus{}Qua \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kp}{sum}\PY{p}{(}\PY{p}{(}Data2Fit\PY{o}{\PYZdl{}}BodyWeight \PY{o}{\PYZhy{}} \PY{k+kp}{mean}\PY{p}{(}Data2Fit\PY{o}{\PYZdl{}}BodyWeight\PY{p}{)}\PY{p}{)}\PY{o}{\PYZca{}}\PY{l+m}{2}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Total sum of squares}
         RSq\PYZus{}Qua \PY{o}{\PYZlt{}\PYZhy{}} \PY{l+m}{1} \PY{o}{\PYZhy{}} \PY{p}{(}RSS\PYZus{}Qua\PY{o}{/}TSS\PYZus{}Qua\PY{p}{)}  \PY{c+c1}{\PYZsh{} R\PYZhy{}squared value}
         
         RSq\PYZus{}Pow 
         RSq\PYZus{}Qua
\end{Verbatim}


    0.90054752976309

    
    0.900302864503218

    
    Not very useful. In general, R\(^2\) is a good measure of model fit, but
cannot be used for model selection -\/- epecially not here, given the
tiby difference in the R\(^2\)'s.

Instead, as discussed in the lecture, we can use the Akaike Information
Criterion (AIC):

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}19}]:} n \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kp}{nrow}\PY{p}{(}Data2Fit\PY{p}{)} \PY{c+c1}{\PYZsh{}set sample size}
         kPow \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kp}{length}\PY{p}{(}coef\PY{p}{(}PowFit\PY{p}{)}\PY{p}{)} \PY{c+c1}{\PYZsh{} get number of parameters in power law model}
         kQua \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kp}{length}\PY{p}{(}coef\PY{p}{(}QuaFit\PY{p}{)}\PY{p}{)} \PY{c+c1}{\PYZsh{} get number of parameters in quadratic model}
         
         AIC\PYZus{}Pow \PY{o}{\PYZlt{}\PYZhy{}} n \PY{o}{*} \PY{k+kp}{log}\PY{p}{(}\PY{p}{(}\PY{l+m}{2} \PY{o}{*} \PY{k+kc}{pi}\PY{p}{)} \PY{o}{/} n\PY{p}{)} \PY{o}{+} n \PY{o}{+} \PY{l+m}{2} \PY{o}{+} n \PY{o}{*} \PY{k+kp}{log}\PY{p}{(}RSS\PYZus{}Pow\PY{p}{)} \PY{o}{+} \PY{l+m}{2} \PY{o}{*} kPow
         AIC\PYZus{}Qua \PY{o}{\PYZlt{}\PYZhy{}} n \PY{o}{*} \PY{k+kp}{log}\PY{p}{(}\PY{p}{(}\PY{l+m}{2} \PY{o}{*} \PY{k+kc}{pi}\PY{p}{)} \PY{o}{/} n\PY{p}{)} \PY{o}{+} n \PY{o}{+} \PY{l+m}{2} \PY{o}{+} n \PY{o}{*} \PY{k+kp}{log}\PY{p}{(}RSS\PYZus{}Qua\PY{p}{)} \PY{o}{+} \PY{l+m}{2} \PY{o}{*} kQua
         AIC\PYZus{}Pow \PY{o}{\PYZhy{}} AIC\PYZus{}Qua
\end{Verbatim}


    -2.1474260812509

    
    Of course, as you might have suspected, we can do this using an in-built
function in R!

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}20}]:} AIC\PY{p}{(}PowFit\PY{p}{)} \PY{o}{\PYZhy{}} AIC\PY{p}{(}QuaFit\PY{p}{)}
\end{Verbatim}


    -2.1474260812509

    
    \emph{So which model wins?} As we had dicussed in the NLLS lecture, a
rule of thumb is that a AIC value difference (typically denoted as
\(\Delta\)AIC) \textgreater{} 2 is a acceptable cutoff for calling a
winner. So the power law (allometric model) is a better fit here. Read
the
\href{https://github.com/mhasoba/TheMulQuaBio/blob/master/Readings/Modelling/JohnsonOmland2004.pdf}{Johnson
\& Omland paper} for more on model selection in Ecology and Evolution.

    \paragraph{Exercises}\label{exercises}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\item
  Calculate the Bayesian Information Criterion (BIC), also know as the
  Schwarz Criterion (see your Lecture notes and the
  \href{https://github.com/mhasoba/TheMulQuaBio/blob/master/Readings/Modelling/JohnsonOmland2004.pdf}{Johnson
  \& Omland paper}, and use \(\Delta\)BIC to select the better fitting
  model.
\item
  Fit a straight line to the same data and compare with the allometric
  and quadratic models.
\item
  Repeat the model comparison (incuding 1-2 above) using the Damselflies
  (Zygoptera) data subset -\/- does the allometric mdoel still win?
\item
  Repeat exercise (e)(i) and (ii) from the
  Section \ref{allom_exercises}, biut with model comparison (e.g., again
  using a quadratic as a alternative model) to establish that the
  relationships are indeed allometric.
\end{enumerate}

    \subsubsection{Fitting growth rate
models}\label{fitting-growth-rate-models}

Let's up the ante and tackle a more complicated NLLS problem - Fitting
population growth rates to data. In general, a population grows
exponentially while its abundance is low and resources are not limiting.
This growth then slows and eventually stops as resources become
limiting. There may also be a time lag before the population growth
really takes off at the start.

We will work with some Bacterial growth data that
\href{https://mhasoba.pythonanywhere.com/pawarlab/default/people}{Tom
Smith}, a PhD student at Silwood, has been generating as part of his
Dissertation research. Bacterial growth in batch culture follows a
distinct set of phases; lag phase, exponential phase and stationary
phase. During the lag phase a suite of transcriptional machinery is
activated, including genes involved in nutrient uptake and metabolic
changes, as bacteria prepare for growth. During the exponential growth
phase, bacteria divide at a constant rate, the population doubling with
each generation. When the carrying capacity of the media is reached,
growth slows and the number of cells in the culture stabilises,
beginning the stationary phase.

Traditionally, growth rate can be measured by plotting out cell numbers
or culture density against time on a semi-log graph and fitting a
straight line through the exponential growth phase - the slope of the
line gives the maximum growth rate (\(r_{max}\)). Models have since been
devised which we can use to describe the whole sigmoidal bacterial
growth curve.

Let's first generate some "data" on the number of bacterial cells as a
function of time taht we can play with:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}21}]:} time \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kt}{c}\PY{p}{(}\PY{l+m}{0}\PY{p}{,} \PY{l+m}{2}\PY{p}{,} \PY{l+m}{4}\PY{p}{,} \PY{l+m}{6}\PY{p}{,} \PY{l+m}{8}\PY{p}{,} \PY{l+m}{10}\PY{p}{,} \PY{l+m}{12}\PY{p}{,} \PY{l+m}{16}\PY{p}{,} \PY{l+m}{20}\PY{p}{,} \PY{l+m}{24}\PY{p}{)} \PY{c+c1}{\PYZsh{} timepoints, in hours}
         log\PYZus{}cells \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kt}{c}\PY{p}{(}\PY{l+m}{3.62}\PY{p}{,} \PY{l+m}{3.62}\PY{p}{,} \PY{l+m}{3.63}\PY{p}{,} \PY{l+m}{4.14}\PY{p}{,} \PY{l+m}{5.23}\PY{p}{,} \PY{l+m}{6.27}\PY{p}{,} \PY{l+m}{7.57}\PY{p}{,} \PY{l+m}{8.38}\PY{p}{,} \PY{l+m}{8.70}\PY{p}{,} \PY{l+m}{8.69}\PY{p}{)} \PY{c+c1}{\PYZsh{} logged cell counts \PYZhy{} more on this below}
         
         data \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kt}{data.frame}\PY{p}{(}time\PY{p}{,} log\PYZus{}cells\PY{p}{)} \PY{o}{+} rnorm\PY{p}{(}\PY{k+kp}{length}\PY{p}{(}time\PY{p}{)}\PY{p}{,}sd\PY{o}{=}\PY{l+m}{.1}\PY{p}{)} \PY{c+c1}{\PYZsh{} add some random error}
         
         \PY{k+kp}{names}\PY{p}{(}data\PY{p}{)} \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kt}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{t\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{LogN\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    We have added a vector of normally distributed errors to emulate random
"sampling errors". Note also that the the assumption of normality of
these errors underlies the statistical analyses of Ordinary NLLS fits
just as it underies Ordinary Least Squares (your standard linear
modelling).

    Plot the data:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}22}]:} ggplot\PY{p}{(}data\PY{p}{,} aes\PY{p}{(}x \PY{o}{=} \PY{k+kp}{t}\PY{p}{,} y \PY{o}{=} LogN\PY{p}{)}\PY{p}{)} \PY{o}{+} geom\PYZus{}point\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_54_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    We will fit three growth models, all of which are known to fit such
population growth data, especially in microbes. These are a modified
Gompertz model (Zwietering et. al., 1990), the Baranyi model (Baranyi,
1993) and the Buchanan model (or three-phase logistic model; Buchanan,
1997). Given a set of cell numbers (N) and times (t), each growth model
can be described in terms of:

\(N_0\): Initial cell culture (Population) density (number of cells per
unit volume)

\(N_{max}\): Maximum culture density (aka "carrying capacity")

\(r_{max}\): Maximum growth rate

\(t_{lag}\): Duration of the lag phase before the population starts
growing exponentially

First let's specify the model functions:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}23}]:} baranyi\PYZus{}model \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kr}{function}\PY{p}{(}\PY{k+kp}{t}\PY{p}{,} r\PYZus{}max\PY{p}{,} N\PYZus{}max\PY{p}{,} N\PYZus{}0\PY{p}{,} t\PYZus{}lag\PY{p}{)}\PY{p}{\PYZob{}}  \PY{c+c1}{\PYZsh{} Baranyi model (Baranyi 1993)}
         \PY{k+kr}{return}\PY{p}{(}N\PYZus{}max \PY{o}{+} \PY{k+kp}{log10}\PY{p}{(}\PY{p}{(}\PY{l+m}{\PYZhy{}1}\PY{o}{+}\PY{k+kp}{exp}\PY{p}{(}r\PYZus{}max\PY{o}{*}t\PYZus{}lag\PY{p}{)} \PY{o}{+} \PY{k+kp}{exp}\PY{p}{(}r\PYZus{}max\PY{o}{*}\PY{k+kp}{t}\PY{p}{)}\PY{p}{)}\PY{o}{/}\PY{p}{(}\PY{k+kp}{exp}\PY{p}{(}r\PYZus{}max\PY{o}{*}\PY{k+kp}{t}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m}{1} \PY{o}{+} \PY{k+kp}{exp}\PY{p}{(}r\PYZus{}max\PY{o}{*}t\PYZus{}lag\PY{p}{)} \PY{o}{*} \PY{l+m}{10}\PY{o}{\PYZca{}}\PY{p}{(}N\PYZus{}max\PY{o}{\PYZhy{}}N\PYZus{}0\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{p}{\PYZcb{}}
         
         
         buchanan\PYZus{}model \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kr}{function}\PY{p}{(}\PY{k+kp}{t}\PY{p}{,} r\PYZus{}max\PY{p}{,} N\PYZus{}max\PY{p}{,} N\PYZus{}0\PY{p}{,} t\PYZus{}lag\PY{p}{)}\PY{p}{\PYZob{}} \PY{c+c1}{\PYZsh{} Buchanan model \PYZhy{} three phase logistic (buchanan 1997)}
           \PY{k+kr}{return}\PY{p}{(}N\PYZus{}0 \PY{o}{+} \PY{p}{(}t \PY{o}{\PYZgt{}=} t\PYZus{}lag\PY{p}{)} \PY{o}{*} \PY{p}{(}t \PY{o}{\PYZlt{}=} \PY{p}{(}t\PYZus{}lag \PY{o}{+} \PY{p}{(}N\PYZus{}max \PY{o}{\PYZhy{}} N\PYZus{}0\PY{p}{)} \PY{o}{*} \PY{k+kp}{log}\PY{p}{(}\PY{l+m}{10}\PY{p}{)}\PY{o}{/}r\PYZus{}max\PY{p}{)}\PY{p}{)} \PY{o}{*} r\PYZus{}max \PY{o}{*} \PY{p}{(}t \PY{o}{\PYZhy{}} t\PYZus{}lag\PY{p}{)}\PY{o}{/}\PY{k+kp}{log}\PY{p}{(}\PY{l+m}{10}\PY{p}{)} \PY{o}{+}
                    \PY{p}{(}t \PY{o}{\PYZgt{}=} t\PYZus{}lag\PY{p}{)} \PY{o}{*} \PY{p}{(}t \PY{o}{\PYZgt{}} \PY{p}{(}t\PYZus{}lag \PY{o}{+} \PY{p}{(}N\PYZus{}max \PY{o}{\PYZhy{}} N\PYZus{}0\PY{p}{)} \PY{o}{*} \PY{k+kp}{log}\PY{p}{(}\PY{l+m}{10}\PY{p}{)}\PY{o}{/}r\PYZus{}max\PY{p}{)}\PY{p}{)} \PY{o}{*} \PY{p}{(}N\PYZus{}max \PY{o}{\PYZhy{}} N\PYZus{}0\PY{p}{)}\PY{p}{)}
         \PY{p}{\PYZcb{}}
         
         
         gompertz\PYZus{}model \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kr}{function}\PY{p}{(}\PY{k+kp}{t}\PY{p}{,} r\PYZus{}max\PY{p}{,} N\PYZus{}max\PY{p}{,} N\PYZus{}0\PY{p}{,} t\PYZus{}lag\PY{p}{)}\PY{p}{\PYZob{}}  \PY{c+c1}{\PYZsh{} Modified gompertz growth model (Zwietering 1990)}
           \PY{k+kr}{return}\PY{p}{(}N\PYZus{}0 \PY{o}{+} \PY{p}{(}N\PYZus{}max \PY{o}{\PYZhy{}} N\PYZus{}0\PY{p}{)} \PY{o}{*} \PY{k+kp}{exp}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{k+kp}{exp}\PY{p}{(}r\PYZus{}max \PY{o}{*} \PY{k+kp}{exp}\PY{p}{(}\PY{l+m}{1}\PY{p}{)} \PY{o}{*} \PY{p}{(}t\PYZus{}lag \PY{o}{\PYZhy{}} \PY{k+kp}{t}\PY{p}{)}\PY{o}{/}\PY{p}{(}\PY{p}{(}N\PYZus{}max \PY{o}{\PYZhy{}} N\PYZus{}0\PY{p}{)} \PY{o}{*} \PY{k+kp}{log}\PY{p}{(}\PY{l+m}{10}\PY{p}{)}\PY{p}{)} \PY{o}{+} \PY{l+m}{1}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{p}{\PYZcb{}}
\end{Verbatim}


    It is important to note that we have written the funcions in log (to the
base 10 - can also be base 2 or natural log) scale. This is because NLLS
fitting often converges better in log scale. The interpretation of each
of the the estimated/fitted paramters does not change if we take a log
of the model's equation.

    Now let's generate some starting values for the NLLS fitting. We did not
pay much attention to what starting values we used in the above example
on fitting an allometric model because the power-law model is easy to
fit using NLLS, and starting far from the optimal parameters does not
matter too much. Here, we derive the starting values by using the actual
data:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}24}]:} N\PYZus{}0\PYZus{}start \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kp}{min}\PY{p}{(}data\PY{o}{\PYZdl{}}LogN\PY{p}{)}
         N\PYZus{}max\PYZus{}start \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kp}{max}\PY{p}{(}data\PY{o}{\PYZdl{}}LogN\PY{p}{)}
         t\PYZus{}lag\PYZus{}start \PY{o}{\PYZlt{}\PYZhy{}} data\PY{o}{\PYZdl{}}\PY{k+kp}{t}\PY{p}{[}\PY{k+kp}{which.max}\PY{p}{(}\PY{k+kp}{diff}\PY{p}{(}\PY{k+kp}{diff}\PY{p}{(}data\PY{o}{\PYZdl{}}LogN\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{]}
         r\PYZus{}max\PYZus{}start \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kp}{max}\PY{p}{(}\PY{k+kp}{diff}\PY{p}{(}data\PY{o}{\PYZdl{}}LogN\PY{p}{)}\PY{p}{)}\PY{o}{/}\PY{k+kp}{mean}\PY{p}{(}\PY{k+kp}{diff}\PY{p}{(}data\PY{o}{\PYZdl{}}\PY{k+kp}{t}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    Now fit the models:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}25}]:} fit\PYZus{}baranyi \PY{o}{\PYZlt{}\PYZhy{}} nlsLM\PY{p}{(}LogN \PY{o}{\PYZti{}} baranyi\PYZus{}model\PY{p}{(}t \PY{o}{=} \PY{k+kp}{t}\PY{p}{,} r\PYZus{}max\PY{p}{,} N\PYZus{}max\PY{p}{,} N\PYZus{}0\PY{p}{,} t\PYZus{}lag\PY{p}{)}\PY{p}{,} data\PY{p}{,}
                       \PY{k+kt}{list}\PY{p}{(}t\PYZus{}lag\PY{o}{=}t\PYZus{}lag\PYZus{}start\PY{p}{,} r\PYZus{}max\PY{o}{=}r\PYZus{}max\PYZus{}start\PY{p}{,} N\PYZus{}0 \PY{o}{=} N\PYZus{}0\PYZus{}start\PY{p}{,} N\PYZus{}max \PY{o}{=} N\PYZus{}max\PYZus{}start\PY{p}{)}\PY{p}{)}
         
         fit\PYZus{}buchanan \PY{o}{\PYZlt{}\PYZhy{}} nlsLM\PY{p}{(}LogN \PY{o}{\PYZti{}} buchanan\PYZus{}model\PY{p}{(}t \PY{o}{=} \PY{k+kp}{t}\PY{p}{,} r\PYZus{}max\PY{p}{,} N\PYZus{}max\PY{p}{,} N\PYZus{}0\PY{p}{,} t\PYZus{}lag\PY{p}{)}\PY{p}{,} data\PY{p}{,}
                                 \PY{k+kt}{list}\PY{p}{(}t\PYZus{}lag\PY{o}{=}t\PYZus{}lag\PYZus{}start\PY{p}{,} r\PYZus{}max\PY{o}{=}r\PYZus{}max\PYZus{}start\PY{p}{,} N\PYZus{}0 \PY{o}{=} N\PYZus{}0\PYZus{}start\PY{p}{,} N\PYZus{}max \PY{o}{=} N\PYZus{}max\PYZus{}start\PY{p}{)}\PY{p}{)}
         
         fit\PYZus{}gompertz \PY{o}{\PYZlt{}\PYZhy{}} nlsLM\PY{p}{(}LogN \PY{o}{\PYZti{}} gompertz\PYZus{}model\PY{p}{(}t \PY{o}{=} \PY{k+kp}{t}\PY{p}{,} r\PYZus{}max\PY{p}{,} N\PYZus{}max\PY{p}{,} N\PYZus{}0\PY{p}{,} t\PYZus{}lag\PY{p}{)}\PY{p}{,} data\PY{p}{,}
                               \PY{k+kt}{list}\PY{p}{(}t\PYZus{}lag\PY{o}{=}t\PYZus{}lag\PYZus{}start\PY{p}{,} r\PYZus{}max\PY{o}{=}r\PYZus{}max\PYZus{}start\PY{p}{,} N\PYZus{}0 \PY{o}{=} N\PYZus{}0\PYZus{}start\PY{p}{,} N\PYZus{}max \PY{o}{=} N\PYZus{}max\PYZus{}start\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Warning message in baranyi\_model(t = t, r\_max, N\_max, N\_0, t\_lag):
“NaNs produced”Warning message in baranyi\_model(t = t, r\_max, N\_max, N\_0, t\_lag):
“NaNs produced”Warning message in baranyi\_model(t = t, r\_max, N\_max, N\_0, t\_lag):
“NaNs produced”
    \end{Verbatim}

    You might get a warning message such as:

\texttt{Warning\ message\ in\ baranyi\_model(t\ =\ t,\ r\_max,\ N\_max,\ N\_0,\ t\_lag):\ “NaNs\ produced”}

This just means that the Baranyi model generated some NaNs during the
fitting procedure for the given data. You can ignore it in this case
(but not always - sometimes these NaNs mean that the equation is wrongly
written, or that it generates NaNs across the whole range of the
x-values, in which case the model is inappropriate for these data).

    Get the model summaries:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}26}]:} \PY{k+kp}{summary}\PY{p}{(}fit\PYZus{}baranyi\PY{p}{)}
         \PY{k+kp}{summary}\PY{p}{(}fit\PYZus{}buchanan\PY{p}{)}
         \PY{k+kp}{summary}\PY{p}{(}fit\PYZus{}gompertz\PY{p}{)}
\end{Verbatim}


    
    \begin{verbatim}

Formula: LogN ~ baranyi_model(t = t, r_max, N_max, N_0, t_lag)

Parameters:
      Estimate Std. Error t value Pr(>|t|)    
t_lag  5.23445    0.39510   13.25 1.14e-05 ***
r_max  1.34149    0.09418   14.24 7.48e-06 ***
N_0    3.54887    0.09488   37.40 2.44e-08 ***
N_max  8.65373    0.09067   95.45 8.91e-11 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.153 on 6 degrees of freedom

Number of iterations to convergence: 17 
Achieved convergence tolerance: 1.49e-08

    \end{verbatim}

    
    
    \begin{verbatim}

Formula: LogN ~ buchanan_model(t = t, r_max, N_max, N_0, t_lag)

Parameters:
      Estimate Std. Error t value Pr(>|t|)    
t_lag  4.13715    0.73469   5.631  0.00134 ** 
r_max  0.99942    0.08768  11.398 2.73e-05 ***
N_0    3.57192    0.16900  21.136 7.31e-07 ***
N_max  8.78296    0.20698  42.433 1.15e-08 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.2927 on 6 degrees of freedom

Number of iterations to convergence: 6 
Achieved convergence tolerance: 1.49e-08

    \end{verbatim}

    
    
    \begin{verbatim}

Formula: LogN ~ gompertz_model(t = t, r_max, N_max, N_0, t_lag)

Parameters:
      Estimate Std. Error t value Pr(>|t|)    
t_lag  5.47660    0.23460   23.34 4.05e-07 ***
r_max  1.46198    0.07087   20.63 8.44e-07 ***
N_0    3.55900    0.05991   59.41 1.53e-09 ***
N_max  8.84733    0.07520  117.64 2.54e-11 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.09735 on 6 degrees of freedom

Number of iterations to convergence: 9 
Achieved convergence tolerance: 1.49e-08

    \end{verbatim}

    
    And see how the fits look:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}27}]:} timepoints \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kp}{seq}\PY{p}{(}\PY{l+m}{0}\PY{p}{,} \PY{l+m}{24}\PY{p}{,} \PY{l+m}{0.1}\PY{p}{)}
         baranyi\PYZus{}points \PY{o}{\PYZlt{}\PYZhy{}} baranyi\PYZus{}model\PY{p}{(}t \PY{o}{=} timepoints\PY{p}{,} r\PYZus{}max \PY{o}{=} coef\PY{p}{(}fit\PYZus{}baranyi\PY{p}{)}\PY{p}{[}\PY{l+s}{\PYZdq{}}\PY{l+s}{r\PYZus{}max\PYZdq{}}\PY{p}{]}\PY{p}{,} N\PYZus{}max \PY{o}{=} coef\PY{p}{(}fit\PYZus{}baranyi\PY{p}{)}\PY{p}{[}\PY{l+s}{\PYZdq{}}\PY{l+s}{N\PYZus{}max\PYZdq{}}\PY{p}{]}\PY{p}{,}
                                         N\PYZus{}0 \PY{o}{=} coef\PY{p}{(}fit\PYZus{}baranyi\PY{p}{)}\PY{p}{[}\PY{l+s}{\PYZdq{}}\PY{l+s}{N\PYZus{}0\PYZdq{}}\PY{p}{]}\PY{p}{,} t\PYZus{}lag \PY{o}{=} coef\PY{p}{(}fit\PYZus{}baranyi\PY{p}{)}\PY{p}{[}\PY{l+s}{\PYZdq{}}\PY{l+s}{t\PYZus{}lag\PYZdq{}}\PY{p}{]}\PY{p}{)}
         buchanan\PYZus{}points \PY{o}{\PYZlt{}\PYZhy{}} buchanan\PYZus{}model\PY{p}{(}t \PY{o}{=} timepoints\PY{p}{,} r\PYZus{}max \PY{o}{=} coef\PY{p}{(}fit\PYZus{}buchanan\PY{p}{)}\PY{p}{[}\PY{l+s}{\PYZdq{}}\PY{l+s}{r\PYZus{}max\PYZdq{}}\PY{p}{]}\PY{p}{,} N\PYZus{}max \PY{o}{=} coef\PY{p}{(}fit\PYZus{}buchanan\PY{p}{)}\PY{p}{[}\PY{l+s}{\PYZdq{}}\PY{l+s}{N\PYZus{}max\PYZdq{}}\PY{p}{]}\PY{p}{,}
                                         N\PYZus{}0 \PY{o}{=} coef\PY{p}{(}fit\PYZus{}buchanan\PY{p}{)}\PY{p}{[}\PY{l+s}{\PYZdq{}}\PY{l+s}{N\PYZus{}0\PYZdq{}}\PY{p}{]}\PY{p}{,} t\PYZus{}lag \PY{o}{=} coef\PY{p}{(}fit\PYZus{}buchanan\PY{p}{)}\PY{p}{[}\PY{l+s}{\PYZdq{}}\PY{l+s}{t\PYZus{}lag\PYZdq{}}\PY{p}{]}\PY{p}{)}
         gompertz\PYZus{}points \PY{o}{\PYZlt{}\PYZhy{}} gompertz\PYZus{}model\PY{p}{(}t \PY{o}{=} timepoints\PY{p}{,} r\PYZus{}max \PY{o}{=} coef\PY{p}{(}fit\PYZus{}gompertz\PY{p}{)}\PY{p}{[}\PY{l+s}{\PYZdq{}}\PY{l+s}{r\PYZus{}max\PYZdq{}}\PY{p}{]}\PY{p}{,} N\PYZus{}max \PY{o}{=} coef\PY{p}{(}fit\PYZus{}gompertz\PY{p}{)}\PY{p}{[}\PY{l+s}{\PYZdq{}}\PY{l+s}{N\PYZus{}max\PYZdq{}}\PY{p}{]}\PY{p}{,}
                                         N\PYZus{}0 \PY{o}{=} coef\PY{p}{(}fit\PYZus{}gompertz\PY{p}{)}\PY{p}{[}\PY{l+s}{\PYZdq{}}\PY{l+s}{N\PYZus{}0\PYZdq{}}\PY{p}{]}\PY{p}{,} t\PYZus{}lag \PY{o}{=} coef\PY{p}{(}fit\PYZus{}gompertz\PY{p}{)}\PY{p}{[}\PY{l+s}{\PYZdq{}}\PY{l+s}{t\PYZus{}lag\PYZdq{}}\PY{p}{]}\PY{p}{)}
         
         df1 \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kt}{data.frame}\PY{p}{(}timepoints\PY{p}{,} baranyi\PYZus{}points\PY{p}{)}
         df1\PY{o}{\PYZdl{}}model \PY{o}{\PYZlt{}\PYZhy{}} \PY{l+s}{\PYZdq{}}\PY{l+s}{Baranyi\PYZdq{}}
         \PY{k+kp}{names}\PY{p}{(}df1\PY{p}{)} \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kt}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{t\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{LogN\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{model\PYZdq{}}\PY{p}{)}
         
         df2 \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kt}{data.frame}\PY{p}{(}timepoints\PY{p}{,} buchanan\PYZus{}points\PY{p}{)}
         df2\PY{o}{\PYZdl{}}model \PY{o}{\PYZlt{}\PYZhy{}} \PY{l+s}{\PYZdq{}}\PY{l+s}{Buchanan\PYZdq{}}
         \PY{k+kp}{names}\PY{p}{(}df2\PY{p}{)} \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kt}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{t\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{LogN\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{model\PYZdq{}}\PY{p}{)}
         
         df3 \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kt}{data.frame}\PY{p}{(}timepoints\PY{p}{,} gompertz\PYZus{}points\PY{p}{)}
         df3\PY{o}{\PYZdl{}}model \PY{o}{\PYZlt{}\PYZhy{}} \PY{l+s}{\PYZdq{}}\PY{l+s}{Gompertz\PYZdq{}}
         \PY{k+kp}{names}\PY{p}{(}df3\PY{p}{)} \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kt}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{t\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{LogN\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{model\PYZdq{}}\PY{p}{)}
         
         model\PYZus{}frame \PY{o}{\PYZlt{}\PYZhy{}} \PY{k+kp}{rbind}\PY{p}{(}df1\PY{p}{,} df2\PY{p}{,} df3\PY{p}{)}
         
         ggplot\PY{p}{(}data\PY{p}{,} aes\PY{p}{(}x \PY{o}{=} \PY{k+kp}{t}\PY{p}{,} y \PY{o}{=} LogN\PY{p}{)}\PY{p}{)} \PY{o}{+}
           geom\PYZus{}point\PY{p}{(}size \PY{o}{=} \PY{l+m}{3}\PY{p}{)} \PY{o}{+}
           geom\PYZus{}line\PY{p}{(}data \PY{o}{=} model\PYZus{}frame\PY{p}{,} aes\PY{p}{(}x \PY{o}{=} \PY{k+kp}{t}\PY{p}{,} y \PY{o}{=} LogN\PY{p}{,} col \PY{o}{=} model\PY{p}{)}\PY{p}{,} size \PY{o}{=} \PY{l+m}{1}\PY{p}{)}
\end{Verbatim}


    
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_66_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \paragraph{Exercises}\label{exercises}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\item
  Calculate the confidence intervals on the parameters of each of the
  three fitted models, and use model selection (using AIC and/or BIC) as
  you did before to find the best-fitting model of the three
\item
  Repeat the model comparison exercise 1000 times (You will have to
  write a loop), and determine whether one model gerally wins more often
  than the others. Note that each rub will generate a slightly different
  dataset, because we are adding a vector of random errors every time
  the "data" are generated.
\item
  Repeat (2), but increase the error by increasing the standard
  deviation of the normal error distributon, and see if there are
  differences in the robustness of the models to sampling/experimental
  errors. You may also want to try chaning the distribution of the
  errors to some non-normal distribtion as see what happens.
\item
  Fit some real data to these models! Import the
  \href{https://github.com/mhasoba/TheMulQuaBio/blob/master/Data/example_growth_data.csv}{following
  dataset on bacterial growth rates} into R:
\end{enumerate}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}28}]:} BacData \PY{o}{\PYZlt{}\PYZhy{}} read.csv\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{../Data/example\PYZus{}growth\PYZus{}data.csv\PYZdq{}}\PY{p}{)}
         
         \PY{k+kp}{head}\PY{p}{(}BacData\PY{p}{)}
         \PY{k+kp}{tail}\PY{p}{(}BacData\PY{p}{)}
\end{Verbatim}


    \begin{tabular}{r|llllll}
 ID & bacterial\_genus & replicate & trait\_name & trait\_value & hour\\
\hline
	 Sch\_AE103\_02 & Flavobacterium   & 1                & Log(cells/mL)    & 5.301030         &  0              \\
	 Sch\_AE103\_02 & Flavobacterium   & 1                & Log(cells/mL)    & 5.301030         &  5              \\
	 Sch\_AE103\_02 & Flavobacterium   & 1                & Log(cells/mL)    & 6.991226         & 10              \\
	 Sch\_AE103\_02 & Flavobacterium   & 1                & Log(cells/mL)    & 8.094820         & 15              \\
	 Sch\_AE103\_02 & Flavobacterium   & 1                & Log(cells/mL)    & 8.358316         & 20              \\
	 Sch\_AE103\_02 & Flavobacterium   & 1                & Log(cells/mL)    & 8.460296         & 25              \\
\end{tabular}


    
    \begin{tabular}{r|llllll}
  & ID & bacterial\_genus & replicate & trait\_name & trait\_value & hour\\
\hline
	963 & Wil\_SP04\_02 & Bacillus        & 4               & Log(cells/mL)   & 7.086360        & 25             \\
	964 & Wil\_SP04\_02 & Bacillus        & 4               & Log(cells/mL)   & 7.322219        & 30             \\
	965 & Wil\_SP04\_02 & Bacillus        & 4               & Log(cells/mL)   & 7.361728        & 35             \\
	966 & Wil\_SP04\_02 & Bacillus        & 4               & Log(cells/mL)   & 7.322219        & 40             \\
	967 & Wil\_SP04\_02 & Bacillus        & 4               & Log(cells/mL)   & 7.260071        & 45             \\
	968 & Wil\_SP04\_02 & Bacillus        & 4               & Log(cells/mL)   & 7.292256        & 50             \\
\end{tabular}


    
    The column \texttt{trait\_value} and \texttt{hour} are your variables of
interest (log cell density and time), respectively. Note that the
\texttt{ID} column will tell you which rows represent one separate
growth experiment. Make sure you have a good look at the data first by
plotting them up (idealy, in a loop).

    That's the end of this NLLS tutorial. Hope you found it useful, and that
it gives you a toe-hold for learning how to fit non-linear models to
your own data.

Also, note that similar to linear models, you can use Non-linear Mixed
Effects statistical methods to fit nonlinear models to data (e.g., using
the \texttt{lme4} and/or \texttt{nlme} packages in R).

    \subsection{Readings and Resources }\label{readings-and-resources}

\begin{itemize}
\tightlist
\item
  Motulsky, Harvey, and Arthur Christopoulos. Fitting models to
  biological data using linear and nonlinear regression: a practical
  guide to curve fitting. OUP USA, 2004.
\item
  Johnson, J. B. \& Omland, K. S. 2004 Model selection in ecology and
  evolution. Trends Ecol. Evol. 19, 101--108.
\item
  The
  \href{https://groups.nceas.ucsb.edu/non-linear-modeling/projects/OrangeTree}{NCEAS
  non-linear modelling working group}
\item
  \href{https://link.springer.com/book/10.1007/b98882}{Mixed-Effects
  Models in S and S-PLUS}
\end{itemize}


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
